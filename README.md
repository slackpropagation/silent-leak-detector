# Silent Leak Detector: Session Analysis Dashboard

This project provides a data-driven dashboard to analyze and visualize user engagement patterns across a digital platform, based on real session-level data exported from Google Analytics. It aims to uncover critical bottlenecks (â€œleaksâ€) in the user journey; specifically, where and why users disengage before converting. By breaking down behavior across dimensions like geography, traffic source, device type, session duration, and funnel stage, this tool helps marketing and product teams:

	â€¢	Quantify user drop-off rates at each key step of the funnel (e.g., browsing, engagement, conversion)
	â€¢	Identify low-performing combinations (e.g., mobile traffic from certain sources)
	â€¢	Highlight high-converting segments worth prioritizing in future campaigns
	â€¢	Provide visual insights to support optimization of UX, content strategy, and ad targeting

Ultimately, the dashboard acts as a â€œleak detectorâ€â€”guiding teams toward practical interventions (like improving mobile UX or tailoring mid-funnel messaging) to maximize conversion and reduce wasted acquisition spend.

## Key Graphs & Insights

### 1. **Country Conversion Map**
This interactive global choropleth map displays the conversion rates by country, based on aggregated session-level data. Each country is shaded according to its conversion performance, making it easy to spot geographic trends at a glance.

The visualization helps teams:
	â€¢	Compare how different markets perform in terms of conversion
	â€¢	Identify high-potential regions that are currently underperforming
	â€¢	Prioritize localization, UX improvements, or targeted campaigns based on regional performance

While a few countriesâ€”such as the United States and some Western European marketsâ€”achieve conversion rates above 1â€“2%, the majority of global traffic converts at less than 0.5%. This stark contrast suggests that expanding ad spend into low-performing regions without first addressing regional UX barriers (e.g., language, loading time, mobile performance) could lead to poor returns on investment. This visualization supports strategic decision-making around international growth and budget allocation.

![Country Conversion Map](outputs/country_conversion_map.png)

### 2. **Funnel Waterfall by Device**

This graph illustrates the user journey through four progressive stages of engagement:
	1.	Browsed â€“ The user visits the site but takes no meaningful action.
	2.	Engaged â€“ The user clicks, scrolls, or navigates within the site.
	3.	Deep Engagement â€“ The user triggers high-intent signals (e.g., watches a full video, views pricing, adds to cart).
	4.	Converted â€“ The user completes a goal (e.g., signs up, makes a purchase).

The waterfall layout breaks down these stages by device type (desktop, mobile, tablet), showing how many users drop off at each step. This lets teams compare funnel efficiency across platforms.

Key insight:
The steepest drop-off happens immediately after the â€œBrowsedâ€ stage, with a large portion of users bouncing without interacting at allâ€”indicating weak initial hooks or unclear CTAs. Only 10â€“14% reach the â€œDeep Engagementâ€ stage, and conversion rates are close to zero across all devices. Mobile and tablet users tend to fall off faster than desktop users, highlighting possible UX friction or slower performance on smaller screens.

This chart helps teams pinpoint which funnel stages and device types need urgent attention, so they can prioritize fixes like faster load times, clearer value props, or device-optimized content.

![Funnel Drop-off](outputs/funnel_dropoff_by_device.png)

#### ğŸ’° Estimated Revenue Lost per Funnel Stage

| Stage                         | Drop-offs | Estimated Revenue Lost ($) |
|------------------------------|-----------|-----------------------------|
| Browsed â†’ Engaged            | 7,239     | $973,164.23                 |
| Engaged â†’ Deep Engagement    | 356       | $47,858.33                  |
| Deep Engagement â†’ Converted  | 682       | $91,683.66                  |

### 3. **Session Duration vs Conversion**

This graph explores the relationship between how long a user stays on the site (session duration) and their likelihood to convert. Sessions are grouped into time buckets (e.g., 0â€“10 seconds, 1â€“5 minutes, etc.), and the corresponding conversion rate is calculated for each.

The purpose of this visualization is to help identify the optimal engagement windowâ€”the amount of time users typically spend before taking actionâ€”and where drop-offs or wasted traffic occur.

Sessions lasting less than 10 seconds almost never result in a conversion, suggesting that these users either bounced immediately due to poor first impressions or werenâ€™t the right audience. Conversion rates begin to rise significantly in the 10â€“20 minute range, peaking during this window and then leveling off or even declining slightly beyond 30 minutesâ€”possibly due to distraction, confusion, or fatigue.

This insight supports the idea that the first 30 seconds should quickly hook users, and the overall experience should aim to sustain engagement for 5â€“20 minutes. Strategies like guided navigation, interactive elements, and personalized content can help keep users in this high-conversion zone.

This chart is especially useful for UX and content teams who want to align design, layout, and information delivery with actual behavioral patterns.

![Session Duration vs Conversion](outputs/session_duration_vs_conversion.png)

### 4. **Source Ã— Device Heatmap**

This heatmap breaks down conversion performance across two dimensions:
	â€¢	Traffic source (e.g., direct, Google Calendar, Outlook, Instagram, paid ads)
	â€¢	Device type (desktop, mobile, tablet)

Each cell represents the conversion rate for a specific source-device combo, color-coded from low to high. The top 10 most frequent sources are included to focus on the most impactful segments.

This visualization is designed to help answer questions like:
	â€¢	Which sources bring high-quality traffic vs. high-volume but low-converting users?
	â€¢	Do certain sources work better on desktop vs. mobile?
	â€¢	Are there device-specific UX issues that may be suppressing conversion?
 
Sources like Google Calendar and Outlookâ€”which are often overlooked in attributionâ€”show surprisingly strong conversion rates, especially on desktop. However, the same sources underperform significantly on mobile and tablet, suggesting possible issues like poor responsiveness, slower load times, or misaligned landing pages on smaller screens.

The broader trend across the heatmap is that mobile and tablet users convert less frequently regardless of the source, pointing to a systemic issue with the mobile experience. This supports prioritizing device-specific optimizations and tailoring campaigns for the platforms where they perform best.

By combining both source and device views, this chart offers targeted optimization opportunitiesâ€”such as reallocating spend, adjusting messaging by platform, or improving cross-device consistency.

![Source Device Heatmap](outputs/source_device_heatmap.png)

## Business Takeaways

This analysis identifies critical leaks, behavioral patterns, and high-impact opportunities across the user journey. It translates complex data into clear strategic priorities for marketing, UX, and product teams.

### Major Leak Points
	â€¢	Biggest leak: The most significant user drop-off occurs immediately after landingâ€”between the â€œBrowsedâ€ and â€œEngagedâ€ stages. A large portion of sessions end without any meaningful interaction, indicating weak first impressions, unclear CTAs, or misaligned landing page content.

### Optimization Goals
	â€¢	Key engagement window: Focus on retaining users within the 5â€“20 minute session range, where conversion probability sharply increases. Keeping users engaged for at least 1â€“2 minutes, and ideally up to 10â€“20, should be a priority.
	â€¢	Use this insight to inform content strategy, interaction design, and onboarding flowâ€”especially on mobile where attention spans are shorter.

### High-Converting Patterns
	â€¢	Top-converting combinations:
	â€¢	Desktop + calendar.google.com
	â€¢	Desktop + outlook.live.com
These niche sources generate relatively fewer sessions but very high conversion rates, suggesting they attract highly qualified traffic. These should be prioritized for campaign expansion or lookalike audience modeling.

### Actionable Fixes
	â€¢	Improve mobile and tablet UX: Address widespread performance gaps across devices. Start by auditing speed, responsiveness, navigation, and form completion on mobile/tablet.
	â€¢	Target mid-funnel drop-off: Many users engage briefly but fail to reach â€œdeep engagement.â€ Strengthen this middle layer with guided flows, product tours, and timely prompts.
	â€¢	Refine ad spend strategy: Shift focus toward source-device pairs with strong ROI. Avoid allocating budget to sources that generate volume but yield low engagement or conversionsâ€”especially on mobile.

## Folder Structure

```
silent-leak-detector/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cleaned_sessions.csv
â”‚   â””â”€â”€ raw_sessions.csv
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ country_conversion_map.png
â”‚   â”œâ”€â”€ funnel_dropoff_by_device.png
â”‚   â”œâ”€â”€ session_duration_vs_conversion.png
â”‚   â””â”€â”€ source_device_heatmap.png
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ Country_Conversion_Map.py
â”‚   â”œâ”€â”€ Funnel_Dropoff_by_Device.py
â”‚   â”œâ”€â”€ Session_Duration_vs_Conversion.py
â”‚   â””â”€â”€ Source_x_Device_Heatmap.py
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ clean_data.py
â”œâ”€â”€ Homepage.py
â”œâ”€â”€ leak_analysis.ipynb
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

## Setup & Requirements

- Python 3.10+
- Install dependencies:
\`\`\`bash
pip install -r requirements.txt
\`\`\`

- To run the dashboard locally:
\`\`\`bash
streamlit run Homepage.py
\`\`\`

## Data Source

Session-level export from Google Analytics  
Date range: up to **May 13, 2025**  
Sensitive user info anonymized

## License

This project is licensed under the MIT License.  
You are free to use, modify, and distribute it with attribution.  
See the [LICENSE](LICENSE) file for full terms.
